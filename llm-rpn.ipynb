{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call ChatGPT.\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def call_gpt(prompt, temperature=0.7):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "    ],\n",
    "    temperature=temperature,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import json\n",
    "from jinja2 import Template\n",
    "\n",
    "# The implementation of the stack-based language.\n",
    "\n",
    "class StackLang:\n",
    "    def __init__(self):\n",
    "        self.stack = []\n",
    "\n",
    "    def push(self, value):\n",
    "        self.stack.append(value)\n",
    "\n",
    "    def pop(self):\n",
    "        if self.stack:\n",
    "            return self.stack.pop()\n",
    "        raise IndexError(\"Pop from an empty stack\")\n",
    "\n",
    "    def MAKE_PROMPT(self):\n",
    "        if len(self.stack) >= 2:\n",
    "            prompt_template = self.pop()\n",
    "            params = self.pop()\n",
    "            template = Template(prompt_template)\n",
    "            self.push(template.render(params))\n",
    "\n",
    "        else:\n",
    "            raise IndexError(\"CALL-ing a model requires 2 params: prompt and model params.\")\n",
    "\n",
    "    def SWAP(self):\n",
    "            if len(self.stack) >= 2:\n",
    "                self.stack[-1], self.stack[-2] = self.stack[-2], self.stack[-1]\n",
    "            else:\n",
    "                raise IndexError(\"Swap needs at least two elements\")\n",
    "\n",
    "\n",
    "    def CALL(self):\n",
    "        if len(self.stack) >= 2:\n",
    "            model = self.pop()\n",
    "            prompt = self.pop()\n",
    "            print('%% Calling model %s with prompt: %s' %(model, prompt))\n",
    "            r = call_gpt(prompt, model['temperature'])\n",
    "            self.push(r)\n",
    "        else:\n",
    "            raise IndexError(\"CALL-ing a model requires 2 params: prompt and model params.\")\n",
    "\n",
    "    def ADD2 (self):\n",
    "        if len(self.stack) >= 2:\n",
    "            d1 = self.pop()\n",
    "            d2 = self.pop()\n",
    "            if isinstance(d1, dict) and isinstance(d2, dict):\n",
    "                self.push({**d1, **d2})\n",
    "            elif isinstance(d1, list) and isinstance(d2, list):\n",
    "                self.push({d1 + d2})\n",
    "            elif isinstance(d1, str) and isinstance(d2, list):\n",
    "                self.push([d1] + d2)\n",
    "            elif isinstance(d1, list) and isinstance(d2, str):\n",
    "                self.push(d1 + [d2]) \n",
    "            elif isinstance(d1, str) and isinstance(d2, str):\n",
    "                self.push([d1, d2])\n",
    "            else:\n",
    "                raise IndexError(\"unexpected case\")\n",
    "        else:\n",
    "            raise IndexError(\"ADD2 requires 2 params on the stack\")\n",
    "\n",
    "\n",
    "    def JSON(self):\n",
    "        if len(self.stack) >= 1:\n",
    "            self.push(json.loads(self.pop()))\n",
    "        else:\n",
    "            raise IndexError(\"JSON requires one param on the stack\")\n",
    "        \n",
    "    def JSON_ARRAY(self):\n",
    "        if len(self.stack) >= 1:\n",
    "            self.push({'array': self.pop()})\n",
    "        else:\n",
    "            raise IndexError(\"JSON_ARRAY requires one param on the stack\")\n",
    "    \n",
    "                      \n",
    "    def DUP(self):\n",
    "        if len(self.stack) >= 1:\n",
    "            self.push(self.stack[0])\n",
    "        else:\n",
    "            raise IndexError(\"DUP requires one param on the stack\")\n",
    "\n",
    "    def OVER(self):\n",
    "        if len(self.stack) >= 2:\n",
    "            self.stack.append(self.stack[-2])\n",
    "        else:\n",
    "            raise IndexError(\"OVER requires 2 params on the stack\")\n",
    "    \n",
    "\n",
    "    def execute(self, commands):\n",
    "        #print(self)\n",
    "\n",
    "        for cmd in commands:\n",
    "            print(self)\n",
    "            if cmd.startswith('\"\"\"'):\n",
    "                self.push(cmd)\n",
    "            elif cmd.startswith('{'):\n",
    "                self.push(json.loads(cmd))\n",
    "            else:\n",
    "                if hasattr(self, cmd):\n",
    "                    getattr(self, cmd)()\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown command: {cmd}\")\n",
    "\n",
    "    def __str__(self):\n",
    "            return str(self.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the file describing the LLM \"program\". \n",
    "\n",
    "def process_file(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    clean_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith('--'):\n",
    "            i = i + 1\n",
    "            continue\n",
    "        if lines[i].startswith('\"\"\"') is False:\n",
    "            clean_lines.append(lines[i].strip())\n",
    "            i = i + 1\n",
    "        else:\n",
    "            j = i\n",
    "            while (j < len(lines) and lines[j].strip().endswith('\"\"\"') is False):\n",
    "                j = j + 1\n",
    "            # clean_lines.append(\"\\n\".join(  [k[:-1] for k in lines[i:j+1] ] ) )\n",
    "            clean_lines.append(\"\\n\".join(lines[i:j+1]).strip())\n",
    "            i = j + 1\n",
    "    return [k for k in clean_lines if k != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['\"\"\"Tell me a joke.\"\"\"']\n",
      "['\"\"\"Tell me a joke.\"\"\"', '\"\"\"Tell me a joke.\"\"\"']\n",
      "['\"\"\"Tell me a joke.\"\"\"', '\"\"\"Tell me a joke.\"\"\"', {'model': 'gpt-3.5', 'temperature': 0.5}]\n",
      "% Calling model {'model': 'gpt-3.5', 'temperature': 0.5} with prompt: \"\"\"Tell me a joke.\"\"\"\n",
      "['\"\"\"Tell me a joke.\"\"\"', 'Why did the scarecrow win an award? Because he was outstanding in his field!']\n",
      "['\"\"\"Tell me a joke.\"\"\"', 'Why did the scarecrow win an award? Because he was outstanding in his field!', '\"\"\"Tell me a joke.\"\"\"']\n",
      "['\"\"\"Tell me a joke.\"\"\"', 'Why did the scarecrow win an award? Because he was outstanding in his field!', '\"\"\"Tell me a joke.\"\"\"', {'model': 'gpt-4', 'temperature': 0.6}]\n",
      "% Calling model {'model': 'gpt-4', 'temperature': 0.6} with prompt: \"\"\"Tell me a joke.\"\"\"\n",
      "['\"\"\"Tell me a joke.\"\"\"', 'Why did the scarecrow win an award? Because he was outstanding in his field!', \"Sure, here's one for you:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\"]\n",
      "['\"\"\"Tell me a joke.\"\"\"', [\"Sure, here's one for you:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the scarecrow win an award? Because he was outstanding in his field!']]\n",
      "[[\"Sure, here's one for you:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the scarecrow win an award? Because he was outstanding in his field!'], '\"\"\"Tell me a joke.\"\"\"']\n",
      "[[\"Sure, here's one for you:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the scarecrow win an award? Because he was outstanding in his field!'], '\"\"\"Tell me a joke.\"\"\"', {'model': 'gpt-4o', 'temperature': 0.7}]\n",
      "% Calling model {'model': 'gpt-4o', 'temperature': 0.7} with prompt: \"\"\"Tell me a joke.\"\"\"\n",
      "[[\"Sure, here's one for you:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the scarecrow win an award? Because he was outstanding in his field!'], \"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\"]\n",
      "\n",
      "[[\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", \"Sure, here's one for you:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the scarecrow win an award? Because he was outstanding in his field!']]\n"
     ]
    }
   ],
   "source": [
    "# We run the program against one of the files.\n",
    "\n",
    "lang = StackLang()\n",
    "commands = process_file('llm3.txt')\n",
    "lang.execute(commands)\n",
    "\n",
    "print()\n",
    "\n",
    "print(lang)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
