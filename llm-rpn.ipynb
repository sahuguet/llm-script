{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call ChatGPT.\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def call_gpt(prompt, temperature=0.7):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "    ],\n",
    "    temperature=temperature,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import json\n",
    "from jinja2 import Template\n",
    "\n",
    "# The implementation of the stack-based language.\n",
    "\n",
    "class StackLang:\n",
    "    def __init__(self):\n",
    "        self.stack = []\n",
    "\n",
    "    def push(self, value):\n",
    "        self.stack.append(value)\n",
    "\n",
    "    def pop(self):\n",
    "        if self.stack:\n",
    "            return self.stack.pop()\n",
    "        raise IndexError(\"Pop from an empty stack\")\n",
    "\n",
    "    def MAKE_PROMPT(self):\n",
    "        if len(self.stack) >= 2:\n",
    "            prompt_template = self.pop()\n",
    "            params = self.pop()\n",
    "            template = Template(prompt_template)\n",
    "            self.push(template.render(params))\n",
    "\n",
    "        else:\n",
    "            raise IndexError(\"CALL-ing a model requires 2 params: prompt and model params.\")\n",
    "\n",
    "    def SWAP(self):\n",
    "            if len(self.stack) >= 2:\n",
    "                self.stack[-1], self.stack[-2] = self.stack[-2], self.stack[-1]\n",
    "            else:\n",
    "                raise IndexError(\"Swap needs at least two elements\")\n",
    "\n",
    "\n",
    "    def CALL(self):\n",
    "        if len(self.stack) >= 2:\n",
    "            model = self.pop()\n",
    "            prompt = self.pop()\n",
    "            print('%% Calling model %s with prompt: %s' %(model, prompt))\n",
    "            r = call_gpt(prompt, model['temperature'])\n",
    "            self.push(r)\n",
    "        else:\n",
    "            raise IndexError(\"CALL-ing a model requires 2 params: prompt and model params.\")\n",
    "\n",
    "    def ADD2 (self):\n",
    "        if len(self.stack) >= 2:\n",
    "            d1 = self.pop()\n",
    "            d2 = self.pop()\n",
    "            if isinstance(d1, dict) and isinstance(d2, dict):\n",
    "                self.push({**d1, **d2})\n",
    "            elif isinstance(d1, list) and isinstance(d2, list):\n",
    "                self.push({d1 + d2})\n",
    "            elif isinstance(d1, str) and isinstance(d2, list):\n",
    "                self.push([d1] + d2)\n",
    "            elif isinstance(d1, list) and isinstance(d2, str):\n",
    "                self.push(d1 + [d2]) \n",
    "            elif isinstance(d1, str) and isinstance(d2, str):\n",
    "                self.push([d1, d2])\n",
    "            else:\n",
    "                raise IndexError(\"unexpected case\")\n",
    "        else:\n",
    "            raise IndexError(\"ADD2 requires 2 params on the stack\")\n",
    "\n",
    "\n",
    "    def JSON(self):\n",
    "        if len(self.stack) >= 1:\n",
    "            self.push(json.loads(self.pop()))\n",
    "        else:\n",
    "            raise IndexError(\"JSON requires one param on the stack\")\n",
    "        \n",
    "    def JSON_ARRAY(self):\n",
    "        if len(self.stack) >= 1:\n",
    "            self.push({'array': self.pop()})\n",
    "        else:\n",
    "            raise IndexError(\"JSON_ARRAY requires one param on the stack\")\n",
    "    \n",
    "                      \n",
    "    def DUP(self):\n",
    "        if len(self.stack) >= 1:\n",
    "            self.push(self.stack[0])\n",
    "        else:\n",
    "            raise IndexError(\"DUP requires one param on the stack\")\n",
    "\n",
    "    def OVER(self):\n",
    "        if len(self.stack) >= 2:\n",
    "            self.stack.append(self.stack[-2])\n",
    "        else:\n",
    "            raise IndexError(\"OVER requires 2 params on the stack\")\n",
    "    \n",
    "\n",
    "    def execute(self, commands):\n",
    "        #print(self)\n",
    "\n",
    "        for cmd in commands:\n",
    "            print(self)\n",
    "            if cmd.startswith('\"\"\"'):\n",
    "                self.push(cmd)\n",
    "            elif cmd.startswith('{'):\n",
    "                self.push(json.loads(cmd))\n",
    "            else:\n",
    "                if hasattr(self, cmd):\n",
    "                    getattr(self, cmd)()\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown command: {cmd}\")\n",
    "\n",
    "    def __str__(self):\n",
    "            return str(self.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the file describing the LLM \"program\". \n",
    "\n",
    "def process_file(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    clean_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith('--'):\n",
    "            i = i + 1\n",
    "            continue\n",
    "        if lines[i].startswith('\"\"\"') is False:\n",
    "            clean_lines.append(lines[i].strip())\n",
    "            i = i + 1\n",
    "        else:\n",
    "            j = i\n",
    "            while (j < len(lines) and lines[j].strip().endswith('\"\"\"') is False):\n",
    "                j = j + 1\n",
    "            # clean_lines.append(\"\\n\".join(  [k[:-1] for k in lines[i:j+1] ] ) )\n",
    "            clean_lines.append(\"\\n\".join(lines[i:j+1]).strip())\n",
    "            i = j + 1\n",
    "    return [k for k in clean_lines if k != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['\"\"\"Tell me a kid appropriate very funny joke.\"\"\"']\n",
      "['\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', '\"\"\"Tell me a kid appropriate very funny joke.\"\"\"']\n",
      "['\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', '\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', {'model': 'gpt-3.5', 'temperature': 0.5}]\n",
      "% Calling model {'model': 'gpt-3.5', 'temperature': 0.5} with prompt: \"\"\"Tell me a kid appropriate very funny joke.\"\"\"\n",
      "['\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', 'Why did the math book look sad?\\n\\nBecause it had too many problems!']\n",
      "['\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', 'Why did the math book look sad?\\n\\nBecause it had too many problems!', '\"\"\"Tell me a kid appropriate very funny joke.\"\"\"']\n",
      "['\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', 'Why did the math book look sad?\\n\\nBecause it had too many problems!', '\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', {'model': 'gpt-4', 'temperature': 0.6}]\n",
      "% Calling model {'model': 'gpt-4', 'temperature': 0.6} with prompt: \"\"\"Tell me a kid appropriate very funny joke.\"\"\"\n",
      "['\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', 'Why did the math book look sad?\\n\\nBecause it had too many problems!', \"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\"]\n",
      "['\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', [\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the math book look sad?\\n\\nBecause it had too many problems!']]\n",
      "[[\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the math book look sad?\\n\\nBecause it had too many problems!'], '\"\"\"Tell me a kid appropriate very funny joke.\"\"\"']\n",
      "[[\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the math book look sad?\\n\\nBecause it had too many problems!'], '\"\"\"Tell me a kid appropriate very funny joke.\"\"\"', {'model': 'gpt-4o', 'temperature': 0.7}]\n",
      "% Calling model {'model': 'gpt-4o', 'temperature': 0.7} with prompt: \"\"\"Tell me a kid appropriate very funny joke.\"\"\"\n",
      "[[\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the math book look sad?\\n\\nBecause it had too many problems!'], 'Why was the math book sad?\\n\\nBecause it had too many problems.']\n",
      "[['Why was the math book sad?\\n\\nBecause it had too many problems.', \"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the math book look sad?\\n\\nBecause it had too many problems!']]\n",
      "[{'array': ['Why was the math book sad?\\n\\nBecause it had too many problems.', \"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the math book look sad?\\n\\nBecause it had too many problems!']}]\n",
      "[{'array': ['Why was the math book sad?\\n\\nBecause it had too many problems.', \"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\", 'Why did the math book look sad?\\n\\nBecause it had too many problems!']}, '\"\"\"Pick the best joke among the jokes.\\n\\n<jokes>\\n\\n{%- for joke in array %}\\n\\n<joke>\\n\\n{{ joke -}}\\n\\n </joke>\\n\\n{% endfor %}\\n\\n</jokes>\\n\\nand explain why\\n\\n\"\"\"']\n",
      "['\"\"\"Pick the best joke among the jokes.\\n\\n<jokes>\\n\\n<joke>\\n\\nWhy was the math book sad?\\n\\nBecause it had too many problems.</joke>\\n\\n\\n\\n<joke>\\n\\nWhy couldn\\'t the bicycle stand up by itself?\\n\\nBecause it was two tired!</joke>\\n\\n\\n\\n<joke>\\n\\nWhy did the math book look sad?\\n\\nBecause it had too many problems!</joke>\\n\\n\\n\\n</jokes>\\n\\nand explain why\\n\\n\"\"\"']\n",
      "['\"\"\"Pick the best joke among the jokes.\\n\\n<jokes>\\n\\n<joke>\\n\\nWhy was the math book sad?\\n\\nBecause it had too many problems.</joke>\\n\\n\\n\\n<joke>\\n\\nWhy couldn\\'t the bicycle stand up by itself?\\n\\nBecause it was two tired!</joke>\\n\\n\\n\\n<joke>\\n\\nWhy did the math book look sad?\\n\\nBecause it had too many problems!</joke>\\n\\n\\n\\n</jokes>\\n\\nand explain why\\n\\n\"\"\"', {'model': 'gpt-4o', 'temperature': 0}]\n",
      "% Calling model {'model': 'gpt-4o', 'temperature': 0} with prompt: \"\"\"Pick the best joke among the jokes.\n",
      "\n",
      "<jokes>\n",
      "\n",
      "<joke>\n",
      "\n",
      "Why was the math book sad?\n",
      "\n",
      "Because it had too many problems.</joke>\n",
      "\n",
      "\n",
      "\n",
      "<joke>\n",
      "\n",
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two tired!</joke>\n",
      "\n",
      "\n",
      "\n",
      "<joke>\n",
      "\n",
      "Why did the math book look sad?\n",
      "\n",
      "Because it had too many problems!</joke>\n",
      "\n",
      "\n",
      "\n",
      "</jokes>\n",
      "\n",
      "and explain why\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "['The best joke among the jokes is:\\n\\n\"Why couldn\\'t the bicycle stand up by itself? Because it was two tired!\"\\n\\nThis joke is clever because it plays on the double meaning of the word \"tired\" - one meaning being physically exhausted, and the other being the two tires of a bicycle. The pun is unexpected']\n"
     ]
    }
   ],
   "source": [
    "# We run the program against one of the files.\n",
    "\n",
    "lang = StackLang()\n",
    "commands = process_file('llm3.txt')\n",
    "lang.execute(commands)\n",
    "\n",
    "print()\n",
    "\n",
    "print(lang)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
