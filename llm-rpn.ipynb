{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call ChatGPT.\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def call_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import json\n",
    "from jinja2 import Template\n",
    "\n",
    "# The implementation of the stack-based language.\n",
    "\n",
    "class StackLang:\n",
    "    def __init__(self):\n",
    "        self.stack = []\n",
    "\n",
    "    def push(self, value):\n",
    "        self.stack.append(value)\n",
    "\n",
    "    def pop(self):\n",
    "        if self.stack:\n",
    "            return self.stack.pop()\n",
    "        raise IndexError(\"Pop from an empty stack\")\n",
    "\n",
    "    def MAKE_PROMPT(self):\n",
    "        if len(self.stack) >= 2:\n",
    "            prompt_template = self.pop()\n",
    "            params = self.pop()\n",
    "            template = Template(prompt_template)\n",
    "            self.push(template.render(params))\n",
    "\n",
    "        else:\n",
    "            raise IndexError(\"CALL-ing a model requires 2 params: prompt and model params.\")\n",
    "\n",
    "    def CALL(self):\n",
    "        if len(self.stack) >= 2:\n",
    "            model = self.pop()\n",
    "            prompt = self.pop()\n",
    "            print('%% Calling model %s with prompt: %s' %(model, prompt))\n",
    "            r = call_gpt(prompt)\n",
    "            self.push(r)\n",
    "        else:\n",
    "            raise IndexError(\"CALL-ing a model requires 2 params: prompt and model params.\")\n",
    "\n",
    "    def ADD2 (self):\n",
    "        if len(self.stack) >= 2:\n",
    "            dict1 = self.pop()\n",
    "            dict2 = self.pop()\n",
    "            self.push({**dict1, **dict2})\n",
    "        else:\n",
    "            raise IndexError(\"ADD2 requires 2 params on the stack\")\n",
    "\n",
    "\n",
    "    def JSON(self):\n",
    "        if len(self.stack) >= 1:\n",
    "            self.push(json.loads(self.pop()))\n",
    "        else:\n",
    "            raise IndexError(\"JSON requires one param on the stack\")\n",
    "                      \n",
    "\n",
    "    def execute(self, commands):\n",
    "        #print(self)\n",
    "\n",
    "        for cmd in commands:\n",
    "            print(self)\n",
    "            if cmd.startswith('\"\"\"'):\n",
    "                self.push(cmd)\n",
    "            elif cmd.startswith('{'):\n",
    "                self.push(json.loads(cmd))\n",
    "            else:\n",
    "                if hasattr(self, cmd):\n",
    "                    getattr(self, cmd)()\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown command: {cmd}\")\n",
    "\n",
    "    def __str__(self):\n",
    "            return str(self.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the file describing the LLM \"program\". \n",
    "\n",
    "def process_file(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    clean_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith('--'):\n",
    "            i = i + 1\n",
    "            continue\n",
    "        if lines[i].startswith('\"\"\"') is False:\n",
    "            clean_lines.append(lines[i].strip())\n",
    "            i = i + 1\n",
    "        else:\n",
    "            j = i\n",
    "            while (j < len(lines) and lines[j].strip().endswith('\"\"\"') is False):\n",
    "                j = j + 1\n",
    "            # clean_lines.append(\"\\n\".join(  [k[:-1] for k in lines[i:j+1] ] ) )\n",
    "            clean_lines.append(\"\\n\".join(lines[i:j+1]).strip())\n",
    "            i = j + 1\n",
    "    return [k for k in clean_lines if k != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'habitat': 'ocean'}]\n",
      "[{'habitat': 'ocean'}, '\"\"\"pick a random animal from the {{habitat}}. Return just the name, as json, using `animal`.\"\"\"']\n",
      "['\"\"\"pick a random animal from the ocean. Return just the name, as json, using `animal`.\"\"\"']\n",
      "['\"\"\"pick a random animal from the ocean. Return just the name, as json, using `animal`.\"\"\"', {'model': 'gpt-3.5', 'temperature': 0.8}]\n",
      "% Calling model {'model': 'gpt-3.5', 'temperature': 0.8} with prompt: \"\"\"pick a random animal from the ocean. Return just the name, as json, using `animal`.\"\"\"\n",
      "['{\\n    \"animal\": \"jellyfish\"\\n}']\n",
      "[{'animal': 'jellyfish'}]\n",
      "[{'animal': 'jellyfish'}, {'genre': 'princess'}]\n",
      "[{'animal': 'jellyfish'}, {'genre': 'princess'}, '\"\"\"Pick a random fictional character from children\\'s book talkinbg about {{genre}}. Return just the name, as json, using `character`.\"\"\"']\n",
      "[{'animal': 'jellyfish'}, '\"\"\"Pick a random fictional character from children\\'s book talkinbg about princess. Return just the name, as json, using `character`.\"\"\"']\n",
      "[{'animal': 'jellyfish'}, '\"\"\"Pick a random fictional character from children\\'s book talkinbg about princess. Return just the name, as json, using `character`.\"\"\"', {'model': 'gpt-3.5', 'temperature': 0.8}]\n",
      "% Calling model {'model': 'gpt-3.5', 'temperature': 0.8} with prompt: \"\"\"Pick a random fictional character from children's book talkinbg about princess. Return just the name, as json, using `character`.\"\"\"\n",
      "[{'animal': 'jellyfish'}, '{\\n  \"character\": \"Cinderella\"\\n}']\n",
      "[{'animal': 'jellyfish'}, {'character': 'Cinderella'}]\n",
      "[{'character': 'Cinderella', 'animal': 'jellyfish'}]\n",
      "[{'character': 'Cinderella', 'animal': 'jellyfish'}, '\"\"\"Make a short story (50 words) featuring {{animal|default(\"frog\")}} and {{character|default(\"shrek\")}}.\"\"\"']\n",
      "['\"\"\"Make a short story (50 words) featuring jellyfish and Cinderella.\"\"\"']\n",
      "['\"\"\"Make a short story (50 words) featuring jellyfish and Cinderella.\"\"\"', {'model': 'gpt-3.5', 'temperature': 0.8}]\n",
      "% Calling model {'model': 'gpt-3.5', 'temperature': 0.8} with prompt: \"\"\"Make a short story (50 words) featuring jellyfish and Cinderella.\"\"\"\n",
      "\n",
      "[\"Once upon a time, Cinderella was invited to a grand underwater ball hosted by the jellyfish queen. She danced gracefully among the glowing creatures, her glass slippers shimmering in the ocean's depths. But when the clock struck midnight, she hurriedly swam back to the surface, leaving behind a trail of bubbles\"]\n"
     ]
    }
   ],
   "source": [
    "# We run the program against one of the files.\n",
    "\n",
    "lang = StackLang()\n",
    "commands = process_file('llm2.txt')\n",
    "lang.execute(commands)\n",
    "\n",
    "print()\n",
    "\n",
    "print(lang)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
